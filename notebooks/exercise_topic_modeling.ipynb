{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Topic Modeling Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:12.932082Z",
     "start_time": "2020-04-29T12:18:12.200358Z"
    }
   },
   "outputs": [],
   "source": [
    "# import TfidfVectorizer and CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# import fetch_20newsgroups from sklearn.datasets\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# import NMF and LatentDirichletAllocation from sklearn\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:14.463840Z",
     "start_time": "2020-04-29T12:18:13.020189Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable called `'no_features'` and set its value to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:15.590700Z",
     "start_time": "2020-04-29T12:18:15.585820Z"
    }
   },
   "outputs": [],
   "source": [
    "no_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a variable `'no_topics'` and set its value to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:16.743304Z",
     "start_time": "2020-04-29T12:18:16.737763Z"
    }
   },
   "outputs": [],
   "source": [
    "no_topics = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a TfidfVectorizer with the following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:17.892838Z",
     "start_time": "2020-04-29T12:18:17.888668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer with specified parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of TfidfVectorizer to transform the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:21.486038Z",
     "start_time": "2020-04-29T12:18:19.135830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the fit_transform method to transform the documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:22.661253Z",
     "start_time": "2020-04-29T12:18:22.656169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the feature names from TfidfVectorizer\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate NMF and fit transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:24.532755Z",
     "start_time": "2020-04-29T12:18:23.661009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate NMF and fit_transform the TF-IDF data\n",
    "num_topics = 100 \n",
    "nmf_model = NMF(n_components=num_topics, random_state=1)\n",
    "nmf_topics = nmf_model.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF topic matrix shape: (11314, 100)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the NMF topic matrix\n",
    "print(f\"NMF topic matrix shape: {nmf_topics.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA w/ Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate a CountVectorizer with following parameters:\n",
    "\n",
    "\n",
    "    * max_df = 0.95\n",
    "    * min_df = 2\n",
    "    * max_features = no_features\n",
    "    * stop_words = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:25.547906Z",
     "start_time": "2020-04-29T12:18:25.540452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with specified parameters\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use fit_transform method of CountVectorizer to transform documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:29.307223Z",
     "start_time": "2020-04-29T12:18:26.637153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the fit_transform method to transform the documents\n",
    "count_matrix = count_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get the features names from TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:18:31.516381Z",
     "start_time": "2020-04-29T12:18:31.498740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the feature names from CountVectorizer\n",
    "count_feature_names = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* instantiate LatentDirichletAllocation and fit transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:03.315322Z",
     "start_time": "2020-04-29T12:18:32.768365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate LatentDirichletAllocation and fit_transform the count data\n",
    "num_topics = 100\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=1)\n",
    "lda_topics = lda_model.fit_transform(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA topic matrix shape: (11314, 100)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the LDA topic matrix\n",
    "print(f\"LDA topic matrix shape: {lda_topics.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create a function `display_topics` that is able to display the top words in a topic for different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display topics for NMF model\n",
    "def display_nmf_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "people know mr 14 different 25 set read let ll\n",
      "Topic 1:\n",
      "does know 14 set different read available 25 question didn\n",
      "Topic 2:\n",
      "know does read question didn years god don drive edu\n",
      "Topic 3:\n",
      "edu 14 file mr set different read available 25 let\n",
      "Topic 4:\n",
      "just a86 things don years going doesn drive edu fact\n",
      "Topic 5:\n",
      "like mr read different 25 file available set ll question\n",
      "Topic 6:\n",
      "just years good doesn don drive edu fact far file\n",
      "Topic 7:\n",
      "use max set don read 10 question years god drive\n",
      "Topic 8:\n",
      "thanks max set read file does question good doesn don\n",
      "Topic 9:\n",
      "good mr different read let available ll key didn question\n",
      "Topic 10:\n",
      "think don set read question didn case drive edu fact\n",
      "Topic 11:\n",
      "god things don mr jesus believe ll new let question\n",
      "Topic 12:\n",
      "problem 14 file question didn years going drive edu fact\n",
      "Topic 13:\n",
      "windows read set different 25 key question g9v doesn don\n",
      "Topic 14:\n",
      "drive max different mr set read 25 file key question\n",
      "Topic 15:\n",
      "time max ll 10 let question didn know key drive\n",
      "Topic 16:\n",
      "don different ll case question going drive edu fact far\n",
      "Topic 17:\n",
      "ve question didn going doesn don drive edu fact far\n",
      "Topic 18:\n",
      "bit max 10 file let available years good drive edu\n",
      "Topic 19:\n",
      "com max mr 25 file read available different let set\n",
      "Topic 20:\n",
      "need max 10 file ll read set available years going\n",
      "Topic 21:\n",
      "used available file question years good don drive edu fact\n",
      "Topic 22:\n",
      "year 14 10 ll new available didn question good fact\n",
      "Topic 23:\n",
      "right 10 question years going don drive edu fact far\n",
      "Topic 24:\n",
      "key make 14 want space let government question didn 25\n",
      "Topic 25:\n",
      "make 14 ll let question didn case going drive edu\n",
      "Topic 26:\n",
      "mail file available let ll years good don drive edu\n",
      "Topic 27:\n",
      "way ll let years going doesn don drive edu fact\n",
      "Topic 28:\n",
      "things say mr going let case didn 15 doesn drive\n",
      "Topic 29:\n",
      "10 b8f a86 question years good drive edu fact far\n",
      "Topic 30:\n",
      "want max mr different make 25 ll let read key\n",
      "Topic 31:\n",
      "really mr read 10 didn years going drive edu fact\n",
      "Topic 32:\n",
      "said mr 25 let file ll 10 set going didn\n",
      "Topic 33:\n",
      "say just ll different let going question didn case don\n",
      "Topic 34:\n",
      "space max 14 file different ll 10 available let read\n",
      "Topic 35:\n",
      "did mr just set 25 different let going got world\n",
      "Topic 36:\n",
      "work max just 14 different file ll 10 available let\n",
      "Topic 37:\n",
      "file a86 g9v max 25 set read world key program\n",
      "Topic 38:\n",
      "believe just file 10 going got question didn drive edu\n",
      "Topic 39:\n",
      "got 14 file ll let going didn don drive edu\n",
      "Topic 40:\n",
      "using 14 file 10 ll available years got drive edu\n",
      "Topic 41:\n",
      "sure just ll make file going let world god doesn\n",
      "Topic 42:\n",
      "question just ll 10 going didn years drive edu fact\n",
      "Topic 43:\n",
      "course little years mr use better want 25 going let\n",
      "Topic 44:\n",
      "going just ll let got didn key g9v doesn don\n",
      "Topic 45:\n",
      "ll b8f g9v just going got good don drive edu\n",
      "Topic 46:\n",
      "probably just ll let different going don drive edu fact\n",
      "Topic 47:\n",
      "years max 10 ll let just new world going got\n",
      "Topic 48:\n",
      "program 14 know file let available ll make 10 going\n",
      "Topic 49:\n",
      "help know mr file 25 years going don drive edu\n",
      "Topic 50:\n",
      "true max set just read file let world going case\n",
      "Topic 51:\n",
      "know problem help 14 just make let ll new got\n",
      "Topic 52:\n",
      "better max a86 just ll best going got god g9v\n",
      "Topic 53:\n",
      "case just ll years going don drive edu fact far\n",
      "Topic 54:\n",
      "software 14 set does available different file 10 let key\n",
      "Topic 55:\n",
      "information max 14 file mr available 10 read key world\n",
      "Topic 56:\n",
      "best 10 world going didn good don drive edu fact\n",
      "Topic 57:\n",
      "number 14 file available 10 let years drive edu fact\n",
      "Topic 58:\n",
      "read ax just file ll let going years don drive\n",
      "Topic 59:\n",
      "doesn just mr different read ll key set let going\n",
      "Topic 60:\n",
      "didn just read ll different let file key world going\n",
      "Topic 61:\n",
      "power max 14 set 10 just let new ll far\n",
      "Topic 62:\n",
      "list 14 file 10 different make available let ll read\n",
      "Topic 63:\n",
      "data ax 14 just file 10 available let government going\n",
      "Topic 64:\n",
      "tell just ll 10 set let world going far government\n",
      "Topic 65:\n",
      "let a86 g9v just ll read far going government best\n",
      "Topic 66:\n",
      "world years 14 little better long time use power just\n",
      "Topic 67:\n",
      "government people little point years just mr time state use\n",
      "Topic 68:\n",
      "lot just people different read ll let going got far\n",
      "Topic 69:\n",
      "00 14 set make good don drive edu fact far\n",
      "Topic 70:\n",
      "look mr just file like ll let best far got\n",
      "Topic 71:\n",
      "try max just file 10 let ll going got don\n",
      "Topic 72:\n",
      "long max just 10 far ll available best got going\n",
      "Topic 73:\n",
      "law 14 people help just file read fact 10 available\n",
      "Topic 74:\n",
      "available a86 g9v different key far best government program tell\n",
      "Topic 75:\n",
      "set ax 14 file just available let far best tell\n",
      "Topic 76:\n",
      "day mr just read jesus different 10 ll key available\n",
      "Topic 77:\n",
      "thing max just people read far going key best got\n",
      "Topic 78:\n",
      "line file just 10 let ll far available best years\n",
      "Topic 79:\n",
      "run max just file 10 ll let available far got\n",
      "Topic 80:\n",
      "little max just mr ll different 10 let read world\n",
      "Topic 81:\n",
      "state max people mr just 14 read file fact ll\n",
      "Topic 82:\n",
      "second 14 people just 10 let fact far going jesus\n",
      "Topic 83:\n",
      "fact just people 14 little years time point true better\n",
      "Topic 84:\n",
      "different ax just time little use like far jesus best\n",
      "Topic 85:\n",
      "come 14 people mr just jesus 25 read like let\n",
      "Topic 86:\n",
      "far people just mr let jesus 25 key going best\n",
      "Topic 87:\n",
      "jesus say god point 14 16 does just people little\n",
      "Topic 88:\n",
      "12 14 10 25 just ll 20 let available new\n",
      "Topic 89:\n",
      "mr ax b8f g9v a86 16 people just 00 fact\n",
      "Topic 90:\n",
      "20 14 god 10 day fact best got years edu\n",
      "Topic 91:\n",
      "15 max 14 say 10 file god ll 25 let\n",
      "Topic 92:\n",
      "16 max 14 10 god ll file available let new\n",
      "Topic 93:\n",
      "25 ax b8f 16 g9v 14 15 just people god\n",
      "Topic 94:\n",
      "14 a86 b8f g9v max people help does god 20\n",
      "Topic 95:\n",
      "point max say people just different does like fact think\n",
      "Topic 96:\n",
      "max ax b8f a86 g9v know 00 like ve said\n",
      "Topic 97:\n",
      "key say 16 use little time point bit just information\n",
      "Topic 98:\n",
      "bit course things say make does help people like believe\n",
      "Topic 99:\n",
      "new b8f max say people does god like fact think\n"
     ]
    }
   ],
   "source": [
    "# display the top words in each topic for the NMF model\n",
    "no_top_words = 10  # Number of top words to display for each topic\n",
    "display_nmf_topics(nmf_model, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* display top 10 words from each topic from LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T12:19:06.842806Z",
     "start_time": "2020-04-29T12:19:06.831721Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to display topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "got just come way like make good don right didn\n",
      "Topic 1:\n",
      "say just don way like come let fact course make\n",
      "Topic 2:\n",
      "said people didn know don like say just time did\n",
      "Topic 3:\n",
      "best way don come just make course good does know\n",
      "Topic 4:\n",
      "list way know don new use point ll need like\n",
      "Topic 5:\n",
      "run just like way don make come course time using\n",
      "Topic 6:\n",
      "ve just like way don know got time years think\n",
      "Topic 7:\n",
      "list long like just good come believe 15 number way\n",
      "Topic 8:\n",
      "problem using time just don try way make does did\n",
      "Topic 9:\n",
      "point just like course good make don come fact know\n",
      "Topic 10:\n",
      "00 20 15 new 10 25 world software list edu\n",
      "Topic 11:\n",
      "probably way don just like make come know little really\n",
      "Topic 12:\n",
      "things way like come don believe know just people doesn\n",
      "Topic 13:\n",
      "using use way used does make work information like available\n",
      "Topic 14:\n",
      "said just like people way don come time believe say\n",
      "Topic 15:\n",
      "sure just like don way make know believe come good\n",
      "Topic 16:\n",
      "use way don just like using know need does make\n",
      "Topic 17:\n",
      "going just way don make like know good right years\n",
      "Topic 18:\n",
      "government think don make fact just way let people does\n",
      "Topic 19:\n",
      "far course way know like just come time don people\n",
      "Topic 20:\n",
      "help way just come know need like does using make\n",
      "Topic 21:\n",
      "work think people going lot ve want time program try\n",
      "Topic 22:\n",
      "new like come just 20 world years time make 15\n",
      "Topic 23:\n",
      "25 way new ll world make list help people com\n",
      "Topic 24:\n",
      "question course way don know come does true like make\n",
      "Topic 25:\n",
      "program long max number use time set information does way\n",
      "Topic 26:\n",
      "key people make good say using want don used doesn\n",
      "Topic 27:\n",
      "line just way like don using try look does need\n",
      "Topic 28:\n",
      "long world way time just come years fact like make\n",
      "Topic 29:\n",
      "lot don like just come way know make things believe\n",
      "Topic 30:\n",
      "mail like make world come new don edu just know\n",
      "Topic 31:\n",
      "12 14 10 15 come new 25 time just like\n",
      "Topic 32:\n",
      "thanks mail need just know does let don jesus law\n",
      "Topic 33:\n",
      "read don just does people time good use make know\n",
      "Topic 34:\n",
      "edu com just like list way world state max don\n",
      "Topic 35:\n",
      "file use set case new used information like 15 right\n",
      "Topic 36:\n",
      "information new like does people number available know used use\n",
      "Topic 37:\n",
      "case fact don just way course know think make like\n",
      "Topic 38:\n",
      "windows using just like use don way come know program\n",
      "Topic 39:\n",
      "time like just don come make years people good think\n",
      "Topic 40:\n",
      "just way make course think law does like time different\n",
      "Topic 41:\n",
      "second just way come make time like new know good\n",
      "Topic 42:\n",
      "know don just let way like time course say read\n",
      "Topic 43:\n",
      "really don just like know way make people think come\n",
      "Topic 44:\n",
      "didn know just way did don make doesn like time\n",
      "Topic 45:\n",
      "work just way like don try make using know doesn\n",
      "Topic 46:\n",
      "need like just does make want new using time work\n",
      "Topic 47:\n",
      "ax max g9v b8f a86 mr 14 25 ll 16\n",
      "Topic 48:\n",
      "people does just course believe thing things say question way\n",
      "Topic 49:\n",
      "little like just new right don time want know try\n",
      "Topic 50:\n",
      "com don just like way try use make need want\n",
      "Topic 51:\n",
      "day just way come little like people don good course\n",
      "Topic 52:\n",
      "don know think just believe try like people long way\n",
      "Topic 53:\n",
      "make don like way know just say want people believe\n",
      "Topic 54:\n",
      "need don know doesn right like going years 20 used\n",
      "Topic 55:\n",
      "data software using like use way time used new point\n",
      "Topic 56:\n",
      "jesus god people say come does fact really way believe\n",
      "Topic 57:\n",
      "tell just like know course people doesn don does make\n",
      "Topic 58:\n",
      "believe way point course true fact used different say does\n",
      "Topic 59:\n",
      "thanks know like does way just make using use believe\n",
      "Topic 60:\n",
      "drive way just know like use max try don make\n",
      "Topic 61:\n",
      "mr don know think day did sure ll said time\n",
      "Topic 62:\n",
      "key use using way used like people fact just don\n",
      "Topic 63:\n",
      "believe does know use using doesn like program time come\n",
      "Topic 64:\n",
      "good don just like way believe know make course come\n",
      "Topic 65:\n",
      "right people just way come make like does believe know\n",
      "Topic 66:\n",
      "years fact make number use way like new time 15\n",
      "Topic 67:\n",
      "10 15 20 make course just like way let know\n",
      "Topic 68:\n",
      "16 drive data use way does run right using second\n",
      "Topic 69:\n",
      "god believe world people say fact does come know way\n",
      "Topic 70:\n",
      "did like fact just people believe make don know course\n",
      "Topic 71:\n",
      "does know like just come way don make using course\n",
      "Topic 72:\n",
      "think don just way like come know good make believe\n",
      "Topic 73:\n",
      "true try way come like using make use think things\n",
      "Topic 74:\n",
      "bit 16 just max like using way use does time\n",
      "Topic 75:\n",
      "let ll come didn like time better just years know\n",
      "Topic 76:\n",
      "set course way like using just use know used don\n",
      "Topic 77:\n",
      "look just like way don come know doesn want people\n",
      "Topic 78:\n",
      "number don used just using 15 time like people use\n",
      "Topic 79:\n",
      "government fact new use come law using used does little\n",
      "Topic 80:\n",
      "20 15 16 10 14 12 25 new way max\n",
      "Topic 81:\n",
      "thing just course way like don know make people come\n",
      "Topic 82:\n",
      "want just don come people way believe know like make\n",
      "Topic 83:\n",
      "used way like just don know good years long time\n",
      "Topic 84:\n",
      "use used run like different new point need does problem\n",
      "Topic 85:\n",
      "different way just don does data know like time right\n",
      "Topic 86:\n",
      "come people don think time just things want say good\n",
      "Topic 87:\n",
      "power like just using don way new 20 use make\n",
      "Topic 88:\n",
      "year years way don just like make good think 20\n",
      "Topic 89:\n",
      "law fact believe use come way right does point just\n",
      "Topic 90:\n",
      "software use good does want time don better work look\n",
      "Topic 91:\n",
      "doesn just problem like know don way try come make\n",
      "Topic 92:\n",
      "state years people just way fact world time come new\n",
      "Topic 93:\n",
      "ll just like way course make know say years new\n",
      "Topic 94:\n",
      "ll going ve don know believe work does number think\n",
      "Topic 95:\n",
      "space program data 15 long new use time information available\n",
      "Topic 96:\n",
      "better just way don like come course think make want\n",
      "Topic 97:\n",
      "like just don come know let way course people case\n",
      "Topic 98:\n",
      "available software use program set edu information number mail data\n",
      "Topic 99:\n",
      "people world just fact way like make think know course\n"
     ]
    }
   ],
   "source": [
    "# display the top words in each topic for the LDA model\n",
    "no_top_words = 10  # Number of top words to display for each topic\n",
    "display_topics(lda_model, count_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch: Use LDA w/ Gensim to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
